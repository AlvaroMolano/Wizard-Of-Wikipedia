{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vnQVDoItAhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "38c02804-b75d-45cc-ef12-7f6b0f40eb07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyDZOLdCtLgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This is the random model for the wizard of wikipedia task. There is no trainable model here only random retrieval of utterances of wizards.\n",
        "This model runs on the test dataset.\n",
        "\n",
        "Deepak Goyal <deepak.16je002137@ece.iitism.ac.in>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo6Ez3ZuuV2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "import string\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDDqf8zBudpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify which machine you are running things\n",
        "running_device='colab'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWM0IrLLujU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw_data_loader(running_device,name):\n",
        "    \"\"\" \n",
        "        Function for loading json data into a list\n",
        "    \"\"\"\n",
        "    \n",
        "    file_dir=''\n",
        "    file_name=name\n",
        "    if running_device=='local':\n",
        "        file_dir='/home/naive/Documents/rohit/Wizard Of Wikipedia/Dataset'\n",
        "    elif running_device=='colab':\n",
        "        file_dir='/content/drive/My Drive/Data/Wizard of Wikipedia/wizard_of_wikipedia'\n",
        "    else:\n",
        "        print(\"Invalid running device\")\n",
        "        return\n",
        "    \n",
        "    data=os.path.join(file_dir,file_name)\n",
        "    \n",
        "    json_data=None\n",
        "    with open(data) as f:\n",
        "        json_data=json.load(f)\n",
        "    \n",
        "    return json_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV4-I0Y3ulCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "80986069-bcde-4b9f-977b-2a6fb8b94fbb"
      },
      "source": [
        "json_data=None\n",
        "\n",
        "print(\"Loading Raw Data into a list....\")\n",
        "\n",
        "t1=time.time()\n",
        "json_data_seen=raw_data_loader(running_device,\"test_random_split.json\")\n",
        "json_data_unseen=raw_data_loader(running_device,\"test_topic_split.json\")\n",
        "t2=time.time()\n",
        "\n",
        "print(\"Loading raw data took \"+str(t2-t1)+\" seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Raw Data into a list....\n",
            "Loading raw data took 2.7358641624450684 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4xZysyNu8Lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "efbc72a6-409d-4e48-8faa-459ba6aa0fc3"
      },
      "source": [
        "print(\"Number of Conversations in seen test topics data: \"+str(len(json_data_seen)))\n",
        "print(\"Number of Conversations in unseen test topics data: \"+str(len(json_data_unseen)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Conversations in seen test topics data: 965\n",
            "Number of Conversations in unseen test topics data: 968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHDDiY4XvH5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class vocabulary:\n",
        "    \"\"\" Creates vocabulary for our corpus data of conversations\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "            self.word2Index(Dictionary): Maps words to tokens\n",
        "            self.num_words(Scalar)     : Number of distinct words in the vocabulary\n",
        "            \n",
        "        \"\"\"\n",
        "        \n",
        "        self.word2Index={'PAD':0,\"<START>\":1,\"<END>\":2}\n",
        "        self.num_words=3\n",
        "        \n",
        "    def addSentence(self,sentence):\n",
        "        \"\"\" \n",
        "            Adds sentences into vocabulary by splitting them\n",
        "        \"\"\"\n",
        "        \n",
        "        for word in sentence.split(\" \"):\n",
        "            self.addWord(word)\n",
        "    \n",
        "    def addWord(self,word):\n",
        "        \n",
        "        if word not in self.word2Index.keys():\n",
        "            self.word2Index[word]=self.num_words\n",
        "            self.num_words+=1  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7wkEqDHxJUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing functions for the data\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "    # thanks to https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
        "    return sentence.translate(str.maketrans('', '', string.punctuation)).lower().strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrpySkEmxMs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56de341b-96ac-447b-936a-2cdd46260c3d"
      },
      "source": [
        "def load_data(data_json):\n",
        "    \n",
        "    context, knowledge, wizard=[],[],[]\n",
        "    dict2cnt={}\n",
        "    count=0\n",
        "    \n",
        "    N=len(data_json)\n",
        "    for id in range(N):\n",
        "        \n",
        "        current_knowledge,current_wizard,context_knowledge,previous_context=[],[],[],[]\n",
        "        tmp_context=[]\n",
        "        \n",
        "        current_conv=data_json[id]\n",
        "        \n",
        "        topic_chosen=remove_punctuation(current_conv['chosen_topic'])\n",
        "        tmp_context.append(topic_chosen)\n",
        "        \n",
        "        conversation_length=len(current_conv['dialog'])\n",
        "        \n",
        "        for i in range(conversation_length):\n",
        "            \n",
        "            if current_conv['dialog'][i]['speaker']=='0_Wizard':\n",
        "                \n",
        "                dict2cnt[count]=len(current_conv['dialog'][i]['retrieved_passages'])\n",
        "                count=count+1\n",
        "                \n",
        "                for x in range(len(current_conv['dialog'][i]['retrieved_passages'])):\n",
        "                    \n",
        "                    idx=current_conv['dialog'][i]['retrieved_passages'][x]\n",
        "                    \n",
        "                    for value in idx.values():\n",
        "                        \n",
        "                        for j in range(len(value)):\n",
        "                            value[j]=remove_punctuation(value[j])\n",
        "                            \n",
        "                        current_knowledge.append(value)\n",
        "                \n",
        "                wizard_dialog=remove_punctuation(current_conv['dialog'][i]['text'])\n",
        "                \n",
        "                current_wizard.append(wizard_dialog)\n",
        "                tmp_context.append(wizard_dialog)\n",
        "            \n",
        "            else:\n",
        "                apperentice_dialog=remove_punctuation(current_conv['dialog'][i]['text'])\n",
        "                tmp_context.append(apperentice_dialog)\n",
        "                \n",
        "        knowledge.append(current_knowledge)\n",
        "        wizard.append(current_wizard)\n",
        "        \n",
        "        final_context=[]\n",
        "        flag=True\n",
        "        \n",
        "        if current_conv['dialog'][0]['speaker']=='0_Wizard':\n",
        "            flag=False\n",
        "        \n",
        "        for i in range(len(tmp_context)):\n",
        "            temp=[]\n",
        "            \n",
        "            for j in range(i+1):\n",
        "                temp.append(tmp_context[j])\n",
        "                \n",
        "            if flag:\n",
        "                if i%2!=0 and len(final_context)<len(current_wizard):\n",
        "                    final_context.append(temp)\n",
        "                    \n",
        "            else:\n",
        "                if i%2==0 and len(final_context)<len(current_wizard):\n",
        "                    final_context.append(temp)\n",
        "        \n",
        "        context.append(final_context)\n",
        "    \n",
        "    return context, knowledge, wizard, dict2cnt\n",
        "\n",
        "print(\"Getting test conversation's context, knowledge, wizard utterances..\")\n",
        "t1=time.time()\n",
        "context, knowledge, wizard, dict2cnt=load_data(json_data_seen)        \n",
        "us_context, us_knowledge, us_wizard, us_dict2cnt=load_data(json_data_unseen)\n",
        "t2=time.time()\n",
        "print(\"This took: \"+str(t2-t1)+\" seconds\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting test conversation's context, knowledge, wizard utterances..\n",
            "This took: 1.1849308013916016 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5KpEg-g5asv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3b15ff8-eefc-4c91-caae-a3473017ba7e"
      },
      "source": [
        "num_wizard=0\n",
        "us_num_wizard=0\n",
        "\n",
        "for i in wizard:\n",
        "    num_wizard+=len(i)\n",
        "\n",
        "for i in us_wizard:\n",
        "    us_num_wizard+=len(i)\n",
        "   \n",
        "\n",
        "print(\"Number of times wizard speaks in seen test dataset: \"+str(num_wizard))\n",
        "print(\"Number of times wizard speaks in unseen test dataset: \"+str(us_num_wizard))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of times wizard speaks in seen test dataset: 2224\n",
            "Number of times wizard speaks in unseen test dataset: 2075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN5Wr-OOyWkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "73a6e48b-63f5-4e2c-8e1a-ee52dad2ef9e"
      },
      "source": [
        "def after_load_process(context,knowledge,wizard,dict2cnt,num):\n",
        "    input_context=[]\n",
        "    input_knowledge=[]\n",
        "    output_wizard=[]\n",
        "    for i in range(len(wizard)):\n",
        "        for c in context[i]:\n",
        "            input_context.append(c)\n",
        "        for k in knowledge[i]:\n",
        "            input_knowledge.append(k)\n",
        "        for w in wizard[i]:\n",
        "            output_wizard.append(w)\n",
        "\n",
        "    input_knowledge2=[]\n",
        "    index=0\n",
        "    for i in range(num):\n",
        "        r=dict2cnt[i]\n",
        "        tmp=[]\n",
        "        fr=index\n",
        "        to=index+r\n",
        "        for j in range(fr,to):\n",
        "            tmp.append(input_knowledge[index])\n",
        "            index=index+1\n",
        "        input_knowledge2.append(tmp)\n",
        "    input_knowledge3=[]\n",
        "    for i in range(len(input_knowledge2)):\n",
        "        g=[]\n",
        "        for j in range(len(input_knowledge2[i])):\n",
        "            s=\"\"\n",
        "            for k in range(len(input_knowledge2[i][j])):\n",
        "                s=s+\" \"+input_knowledge2[i][j][k]\n",
        "            s=s.strip()\n",
        "            g.append(s)\n",
        "        input_knowledge3.append(g)\n",
        "    return input_context,input_knowledge3,output_wizard\n",
        "\n",
        "print(\"Converting the extracted sentences into lists...\")\n",
        "t1=time.time()\n",
        "final_context, final_knowledge, final_wizard=after_load_process(context,knowledge,wizard,dict2cnt,num_wizard)\n",
        "us_final_context, us_final_knowledge, us_final_wizard=after_load_process(us_context,us_knowledge,us_wizard,us_dict2cnt,us_num_wizard)\n",
        "t2=time.time()\n",
        "print(\"This took: \"+str(t2-t1)+\" seconds\")\n",
        "    \n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting the extracted sentences into lists...\n",
            "This took: 0.19616341590881348 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6uRQY8rxr9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length=70\n",
        "\n",
        "def process(sentence):\n",
        "    \"\"\"\n",
        "        Preprocessing sentencing to make them of equal length and appending and terminating them with\n",
        "        start (<START>) and end (<END>) token.\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    words=sentence.split()\n",
        "    sentence_length=max_length-2\n",
        "    if len(words)<=sentence_length:\n",
        "        for i in range(sentence_length-len(words)):\n",
        "            words.append(\"PAD\")\n",
        "    else:\n",
        "        words=words[:sentence_length]\n",
        "    \n",
        "    res=\"\"\n",
        "    words.append(\"<END>\")\n",
        "    words.insert(0,\"<START>\")\n",
        "    assert len(words)==max_length\n",
        "    for w in words:\n",
        "        res=res+\" \"+w\n",
        "    res=res.strip()\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GdtN54S6oG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "63700e9a-99cd-4c88-aedb-0428b5ed5c20"
      },
      "source": [
        "vocab=vocabulary()\n",
        "\n",
        "def process_loaded(input_context,input_knowledge,output_wizard):\n",
        "    \"\"\" Processing sentences and forming vocabulary\n",
        "    \"\"\"\n",
        "    \n",
        "    for i in range(len(output_wizard)):\n",
        "        output_wizard[i]=process(output_wizard[i])\n",
        "        vocab.addSentence(output_wizard[i])\n",
        "        assert len(output_wizard[i].split())==max_length\n",
        "    \n",
        "    for i in range(len(input_knowledge)):\n",
        "        for j in range(len(input_knowledge[i])):\n",
        "            input_knowledge[i][j]=process(input_knowledge[i][j])\n",
        "            vocab.addSentence(input_knowledge[i][j])\n",
        "            assert len(input_knowledge[i][j].split())==max_length\n",
        "        \n",
        "    for i in range(len(input_context)):\n",
        "        for j in range(len(input_context[i])):\n",
        "            input_context[i][j]=process(input_context[i][j])\n",
        "            vocab.addSentence(input_context[i][j])\n",
        "            assert len(input_context[i][j].split())==max_length\n",
        "    return input_context, input_knowledge, output_wizard\n",
        "\n",
        "print(\"Processing fetched sentences...\")\n",
        "t1=time.time()\n",
        "p_context,p_knowledge,p_wizard=process_loaded(final_context,final_knowledge,final_wizard)\n",
        "us_p_context,us_p_knowledge,us_p_wizard=process_loaded(us_final_context,us_final_knowledge,us_final_wizard)\n",
        "t2=time.time()\n",
        "print(\"This process took: \"+str(t2-t1))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing fetched sentences...\n",
            "This process took: 3.142613649368286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp1JUr0-7np9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "554b25b8-6a48-400a-a29f-2acf9a75898f"
      },
      "source": [
        "##########################SANITY CHECK##########################\n",
        "\n",
        "def sanity_check(context,knowledge,wizard,num,data):\n",
        "    assert len(wizard)==num\n",
        "    assert len(context)==num\n",
        "    assert len(knowledge)==num\n",
        "\n",
        "    print(\"Running Sanity Checks on the data...\"+data)\n",
        "\n",
        "    t1=time.time()\n",
        "\n",
        "    for i in range(len(wizard)):\n",
        "        assert len(wizard[i].split())==max_length\n",
        "\n",
        "    for i in range(len(context)):\n",
        "        for j in range(len(context[i])):\n",
        "            assert len(context[i][j].split())==max_length\n",
        "\n",
        "    for i in range(len(knowledge)):\n",
        "        for j in range(len(knowledge[i])):\n",
        "            assert len(knowledge[i][j].split())==max_length\n",
        "\n",
        "t1=time.time()\n",
        "\n",
        "sanity_check(p_context,p_knowledge,p_wizard,num_wizard,\"test seen data\")\n",
        "sanity_check(us_p_context,us_p_knowledge,us_p_wizard,us_num_wizard,\"test unseen data\")\n",
        "\n",
        "t2=time.time()\n",
        "print(\"Everything seems fine.\")        \n",
        "print(\"Sanity Checks took: \"+str(t2-t1)+\" seconds\")\n",
        " \n",
        "################################################################"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Sanity Checks on the data...test seen data\n",
            "Running Sanity Checks on the data...test unseen data\n",
            "Everything seems fine.\n",
            "Sanity Checks took: 0.2103896141052246 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MctR1pUDCPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}